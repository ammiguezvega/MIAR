{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K62ildjpk6rV"
      },
      "source": [
        "### EXAMEN - Convocatoria 1 - Programación\n",
        "Resolver el siguiente problema de regresión lineal."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VpRCOIYGlfER"
      },
      "source": [
        "#### 1) Generación de los datos (1 punto):\n",
        "\n",
        "Mediante la función `make_regressión` de sklearn, consultar su como emplearla para generar un conjunto de 2000 datos, 10 características, un ruido de 1 y fijar el parámetro ramdom_state=42."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "BBE37Okbla3M"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Dimensiones de X: (2000, 10)\n",
            "Dimensiones de y: (2000,)\n"
          ]
        }
      ],
      "source": [
        "# Generación de datos\n",
        "from sklearn.datasets import make_regression\n",
        "\n",
        "# Generar datos de regresión\n",
        "X, y = make_regression(n_samples=2000, n_features=10, noise=1, random_state=42)\n",
        "\n",
        "# Verificar las dimensiones de X e y\n",
        "print(\"Dimensiones de X:\", X.shape)\n",
        "print(\"Dimensiones de y:\", y.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ve6u0_uAk6rX"
      },
      "source": [
        "#### 2) Partición de datos externa (1 punto)\n",
        "Realizar una partición externa de tipo hold-out seleccionando un 20% de los datos para test (fijar una semilla en 42)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "weIX4nYHk6rY"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Dimensiones de X_train: (1600, 10)\n",
            "Dimensiones de X_test: (400, 10)\n",
            "Dimensiones de y_train: (1600,)\n",
            "Dimensiones de y_test: (400,)\n"
          ]
        }
      ],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Dividir el conjunto de datos en entrenamiento y test\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Verificar las dimensiones de los conjuntos de entrenamiento y test\n",
        "print(\"Dimensiones de X_train:\", X_train.shape)\n",
        "print(\"Dimensiones de X_test:\", X_test.shape)\n",
        "print(\"Dimensiones de y_train:\", y_train.shape)\n",
        "print(\"Dimensiones de y_test:\", y_test.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9kMAkw6fk6ra"
      },
      "source": [
        "#### 3) Estandarización de los datos de train y test (1 punto)\n",
        "Utilizar el método StandardScaler()."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0LWG3pMak6ra"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Dimensiones de X_train_scaled: (1600, 10)\n",
            "Dimensiones de X_test_scaled: (400, 10)\n"
          ]
        }
      ],
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# Inicializar el StandardScaler\n",
        "scaler = StandardScaler()\n",
        "\n",
        "# Ajustar el scaler a los datos de entrenamiento y transformar los datos de entrenamiento\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "\n",
        "# Aplicar la misma transformación a los datos de test\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# Verificar las dimensiones de los conjuntos de entrenamiento y test\n",
        "print(\"Dimensiones de X_train_scaled:\", X_train_scaled.shape)\n",
        "print(\"Dimensiones de X_test_scaled:\", X_test_scaled.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jDpAlUXek6rb"
      },
      "source": [
        "#### 4) Creación de modelos e hiperparametrización mediante el método de sklearn GridSearchCV (4 puntos):\n",
        "\n",
        "Instrucciones:\n",
        "\n",
        "- Cree los siguientes modelos de regresión en un diccionario:\n",
        "  - Regresión Lineal (OLS).\n",
        "  - Regresión Lasso\n",
        "  - Regresión Rígida\n",
        "  - Vecinos más cercanos (KNN)\n",
        "\n",
        "- Cree las siguiente métricas en un diccionario para evaluar:\n",
        "  - MAE\n",
        "  - MSE\n",
        "  - RMSE\n",
        "  - R2\n",
        "\n",
        "- Haga una búsqueda de los siguientes hiperparámetros mediante GridSearchCV:\n",
        "\n",
        "```\n",
        "# Hiperparametros\n",
        "parameters = {'OLS':{},\n",
        "              'Lasso':{'alpha':(0.1,0.5,1,5,10,50,100)},\n",
        "              'Ridge':{'alpha':(0.1,0.5,1,5,10,50,100)},\n",
        "              'KNN':{'n_neighbors':np.arange(1,15),\n",
        "                     'weights':('uniform','distance'),\n",
        "                     'metric':('euclidean','manhattan','cosine')\n",
        "                     }\n",
        "              }\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Modelo: OLS\n",
            "\tMétrica: MAE\n",
            "\t\tResultado: 0.7731\n",
            "\t\tMejores hiperparámetros: {}\n",
            "\tMétrica: MSE\n",
            "\t\tResultado: 0.9534\n",
            "\t\tMejores hiperparámetros: {}\n",
            "\tMétrica: RMSE\n",
            "\t\tResultado: 0.9764\n",
            "\t\tMejores hiperparámetros: {}\n",
            "\tMétrica: R2\n",
            "\t\tResultado: 1.0000\n",
            "\t\tMejores hiperparámetros: {}\n",
            "Modelo: Lasso\n",
            "\tMétrica: MAE\n",
            "\t\tResultado: 150.7415\n",
            "\t\tMejores hiperparámetros: {'alpha': 100}\n",
            "\tMétrica: MSE\n",
            "\t\tResultado: 35093.2635\n",
            "\t\tMejores hiperparámetros: {'alpha': 100}\n",
            "\tMétrica: RMSE\n",
            "\t\tResultado: 1.0173\n",
            "\t\tMejores hiperparámetros: {'alpha': 0.1}\n",
            "\tMétrica: R2\n",
            "\t\tResultado: 1.0000\n",
            "\t\tMejores hiperparámetros: {'alpha': 0.1}\n",
            "Modelo: Ridge\n",
            "\tMétrica: MAE\n",
            "\t\tResultado: 8.6452\n",
            "\t\tMejores hiperparámetros: {'alpha': 100}\n",
            "\tMétrica: MSE\n",
            "\t\tResultado: 115.6398\n",
            "\t\tMejores hiperparámetros: {'alpha': 100}\n",
            "\tMétrica: RMSE\n",
            "\t\tResultado: 0.9759\n",
            "\t\tMejores hiperparámetros: {'alpha': 0.1}\n",
            "\tMétrica: R2\n",
            "\t\tResultado: 1.0000\n",
            "\t\tMejores hiperparámetros: {'alpha': 0.1}\n",
            "Modelo: KNN\n",
            "\tMétrica: MAE\n",
            "\t\tResultado: 98.6919\n",
            "\t\tMejores hiperparámetros: {'metric': 'cosine', 'n_neighbors': 1, 'weights': 'uniform'}\n",
            "\tMétrica: MSE\n",
            "\t\tResultado: 15400.2781\n",
            "\t\tMejores hiperparámetros: {'metric': 'cosine', 'n_neighbors': 1, 'weights': 'uniform'}\n",
            "\tMétrica: RMSE\n",
            "\t\tResultado: 67.6749\n",
            "\t\tMejores hiperparámetros: {'metric': 'cosine', 'n_neighbors': 14, 'weights': 'distance'}\n",
            "\tMétrica: R2\n",
            "\t\tResultado: 0.8720\n",
            "\t\tMejores hiperparámetros: {'metric': 'cosine', 'n_neighbors': 14, 'weights': 'distance'}\n"
          ]
        }
      ],
      "source": [
        "from math import sqrt\n",
        "from sklearn.linear_model import LinearRegression, Lasso, Ridge\n",
        "from sklearn.neighbors import KNeighborsRegressor\n",
        "from sklearn.metrics import make_scorer, mean_absolute_error, mean_squared_error, r2_score\n",
        "from sklearn.model_selection import GridSearchCV, KFold\n",
        "import numpy as np\n",
        "\n",
        "# Crear modelos de regresión en un diccionario\n",
        "models = {\n",
        "    \"OLS\": LinearRegression(),\n",
        "    \"Lasso\": Lasso(random_state=42),\n",
        "    \"Ridge\": Ridge(random_state=42),\n",
        "    \"KNN\": KNeighborsRegressor()\n",
        "}\n",
        "\n",
        "# Crear metricas de evaluación en un diccionario\n",
        "metrics = {\n",
        "    \"MAE\": mean_absolute_error,\n",
        "    \"MSE\": mean_squared_error,\n",
        "    \"RMSE\": lambda y_true, y_pred: sqrt(mean_squared_error(y_true, y_pred)),\n",
        "    \"R2\": r2_score\n",
        "}\n",
        "\n",
        "# Hiperparámetros\n",
        "parameters = {\n",
        "    'OLS':{},\n",
        "    'Lasso':{'alpha':(0.1,0.5,1,5,10,50,100)},\n",
        "    'Ridge':{'alpha':(0.1,0.5,1,5,10,50,100)},\n",
        "    'KNN':{'n_neighbors':np.arange(1,15), 'weights':('uniform','distance'), 'metric':('euclidean','manhattan','cosine')}\n",
        "}\n",
        "\n",
        "# Crear un diccionario para guardar los resultados de la evaluación de los modelos\n",
        "results = {}\n",
        "\n",
        "# Crear un diccionario para guardar los resultados de la búsqueda de hiperparámetros\n",
        "best_params = {}\n",
        "\n",
        "# Iterar sobre los modelos\n",
        "for model_name, model in models.items():\n",
        "    print(f\"Modelo: {model_name}\")\n",
        "    results[model_name] = {}\n",
        "    best_params[model_name] = {}\n",
        "\n",
        "    # Iterar sobre las métricas\n",
        "    for metric_name, metric in metrics.items():\n",
        "        print(f\"\\tMétrica: {metric_name}\")\n",
        "\n",
        "        # Crear un objeto scorer a partir de la métrica\n",
        "        if metric_name == \"RMSE\":\n",
        "            # Para RMSE, usamos greater_is_better=False porque queremos minimizar el error\n",
        "            scorer = make_scorer(metric, greater_is_better=False)\n",
        "        else:\n",
        "            scorer = make_scorer(metric)\n",
        "\n",
        "        # Inicializar el GridSearchCV con el modelo, los hiperparámetros y la métrica a evaluar\n",
        "        grid_search = GridSearchCV(model, parameters[model_name], scoring=scorer, cv=KFold(n_splits=5, shuffle=True, random_state=42))\n",
        "\n",
        "        # Ajustar el GridSearchCV a los datos de entrenamiento\n",
        "        grid_search.fit(X_train_scaled, y_train)\n",
        "        \n",
        "        # Guardar los mejores hiperparámetros\n",
        "        best_params[model_name][metric_name] = grid_search.best_params_\n",
        "        \n",
        "        # Evaluar el modelo con los mejores hiperparámetros en los datos de test\n",
        "        y_pred = grid_search.predict(X_test_scaled)\n",
        "        results[model_name][metric_name] = metric(y_test, y_pred)\n",
        "\n",
        "        print(f\"\\t\\tResultado: {results[model_name][metric_name]:.4f}\")\n",
        "        print(f\"\\t\\tMejores hiperparámetros: {best_params[model_name][metric_name]}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tT0yuV7Lk6rc"
      },
      "source": [
        "#### 5) Evaluación de los modelos sobre el conjunto de test (2 puntos)\n",
        "- Entrenar los modelos anteriores utilizando todos los datos de entrenamiento y quédese con el mejor modelo de cada uno de los modelos de regresión arrojados por GridSearchCV. Es decir, debe tener un mejor modelo por cada regresión (OLS, Lasso, Rígida y KNN)\n",
        "- Evaluar su rendimiento sobre el conjunto de test mostrando para cada uno de los modelos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WSsAww8_k6rd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Modelo: OLS\n",
            "\tMAE: 0.7731\n",
            "\tMSE: 0.9534\n",
            "\tRMSE: 0.9764\n",
            "\tR2: 1.0000\n",
            "Modelo: Lasso\n",
            "\tMAE: 0.8031\n",
            "\tMSE: 1.0349\n",
            "\tRMSE: 1.0173\n",
            "\tR2: 1.0000\n",
            "Modelo: Ridge\n",
            "\tMAE: 0.7727\n",
            "\tMSE: 0.9524\n",
            "\tRMSE: 0.9759\n",
            "\tR2: 1.0000\n",
            "Modelo: KNN\n",
            "\tMAE: 50.0401\n",
            "\tMSE: 4579.8916\n",
            "\tRMSE: 67.6749\n",
            "\tR2: 0.8720\n",
            "\n",
            "--------------------------\n",
            "\n",
            "Cross-validation interno con 5 bolsas\n",
            "OLS Accuracy: 1.0000 +/- 0.0000\n",
            "Lasso Accuracy: 1.0000 +/- 0.0000\n",
            "Ridge Accuracy: 1.0000 +/- 0.0000\n",
            "KNN Accuracy: 0.8622 +/- 0.0085\n"
          ]
        }
      ],
      "source": [
        "# Crear un diccionario para guardar los mejores modelos\n",
        "from sklearn.model_selection import cross_val_score\n",
        "\n",
        "\n",
        "best_models = {}\n",
        "\n",
        "# Iterar sobre los modelos y entrenar con los mejores hiperparámetros\n",
        "for model_name, model in models.items():\n",
        "    # Crear un modelo con los mejores hiperparámetros \n",
        "    best_model = model.set_params(**best_params[model_name]['R2']) # Usamos R2 como métrica de referencia\n",
        "\n",
        "    # Entrenar el modelo con todos los datos de entrenamiento\n",
        "    best_model.fit(X_train_scaled, y_train)\n",
        "    \n",
        "    # Guardar el mejor modelo\n",
        "    best_models[model_name] = best_model\n",
        "\n",
        "# Evaluar los mejores modelos en el conjunto de test\n",
        "for model_name, model in best_models.items():\n",
        "    print(f\"Modelo: {model_name}\")\n",
        "    \n",
        "    # Predecir los valores de y en el conjunto de test\n",
        "    y_pred = model.predict(X_test_scaled)\n",
        "    \n",
        "    # Iterar sobre las métricas\n",
        "    for metric_name, metric in metrics.items():\n",
        "        # Calcular la métrica\n",
        "        result = metric(y_test, y_pred)\n",
        "        print(f\"\\t{metric_name}: {result:.4f}\")\n",
        "\n",
        "print(\"\\n--------------------------\\n\")\n",
        "print(\"Cross-validation interno con 5 bolsas\")\n",
        "\n",
        "# Hacer cross-validation para cada modelo y calcular la accuracy para seleccionar el mejor modelo\n",
        "for model_name, model in best_models.items():\n",
        "    scores = cross_val_score(model, X_train_scaled, y_train, cv=KFold(n_splits=5, shuffle=True, random_state=42), scoring=make_scorer(r2_score))\n",
        "    # Calcular la accuracy \n",
        "    print(model_name + ' Accuracy: %0.4f +/- %0.4f' % (scores.mean(), scores.std()))\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ebka8YtDk6rd"
      },
      "source": [
        "#### 6) Interpretación de resultados (1 puntos)\n",
        "* Justifica brevemente cuál de los modelos utilizarías para ponerlo en producción"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XVoVPCNTk6re"
      },
      "source": [
        "Los algoritmos de Regresión Lineal (OLS), Lasso y Ridge tienen un rendimiento muy similar, con valores de R2 practicamente igual a 1 y una gran accuracy en validación interna cruzada, lo cual indica que son modelos estables y que generalizan bien. KNN tiene un desempeño bastante peor por lo que queda descartado.\n",
        "Entre estos tres algoritmos (OLS, Lasso y Ridge), vemos que Lasso tiene errores ligeramente más altos que OLS y Ridge con lo que también podríamos descartarlo en base a esto.\n",
        "Como comparación final, vemos que OLS y Ridge son prácticamente identicos en cuanto a métricas, Ridge teniendo MAE, MSE y RMSE ligerísimamente inferiores a OLS (diferencias prácticamente negligibles)\n",
        "\n",
        "Basado en este análisis, podemos concluir que ambos modelos son buenas elecciones para desplegar en Producción pero debido a la simplicidad de la Regresión Lineal (OLS), lo fácil de interpretar que resulta, su eficiencia computacional y que no necesita de ajuste de hiperparámetros, lo cuál simplifica su mantenimiento, concluímos que **OLS** debe ser el modelo elegido."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
